{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling - Wrangle Report\n",
    "**by Katrin Haller/ September 2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data wrangling project I have learned a lot and it was a very challenging one. \n",
    "\n",
    "First, I read carefully and set up everything as needed. As described in the step-by-step guideline I gathered the twitter_archive_enhanced.csv and the image_predictions.tsv. Then I started to get familiar with the data. Now I decided to set up a new Twitter account for the purpose to get a Developer account on Twitter. Following the instructions on Twitter and Udacity I got my keys and tokens to query the additional tweets with the Twitter API. I saved these tweets to two different lists, one for the gathered tweets and one for the gathered failed tweets, which cannot be found. \n",
    "Then I wrote the JSON data into a new tweet_json.txt and the failed tweets into tweet_failed.txt. I red the data into a Pandas dataframe. First I did this without reading line-by-line since this seems to be a simple solution. Now I got the info about this dataframe and reduced this to the columns of interest, here tweet_id, retweet_count and favorite_count. Now I read the data line-by-line and renamed the columns to retweets and favorites as it is shorter. Now that I had all data I needed, gathering was done.\n",
    "\n",
    "I started assessing the data by visually looking at columns, rows, headers, datatypes and duplicated data for each of the datasets. Now that I got an idea I startet to check programmatically and first figured out quality and tidiness issues and sorted these issues. \n",
    "\n",
    "Now I began the cleaning process of the data, which took the most of the time. But before that I copied all datasets for the cleaning. I started with cleaning for datatype issues, then merged the first two tables, later droping columns, datatypes again, cleaning for names, created new columns, split columns, condensed columns and as a last step merged with the last dataframe.\n",
    "\n",
    "I stored the data to .csv and started analyzing the cleaned master dataframe (twitter_archive_master). Then I started to make up my mind for interesting insights, analyzed and plotted the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
